\chapter{Introduction}

Most of Internet traffic is content, and most of Internet connected hosts are mobile. It is estimated that a vast majority of network traffic on the Internet is content, with videos alone expected to account for 80\% of all traffic by 2018 \cite{cisco-videogrowth}. By 2020, the number of Internet connected mobile end hosts is expected to grow to nearly 10 billion and the total traffic originated by mobiles is poised to approach that by wired devices \cite{cisco-vni}.


A content-dominated, highly mobile Internet needs several forms of infrastructure support. It needs network infrastructure with sufficient capacity to carry traffic to end users. It needs server infrastructure to sustain and accelerate delivery of content. In the presence of frequent network mobility or changing addresses, infrastructure support becomes necessary for establishing and maintaining connections. This thesis focuses on the design of services that manage the infrastructure resources achieve the desired goals.

\section{Characteristics of infrastructure}

Our service designs are strongly influenced by the following characteristices of the infrastructures.

\textbf{Cost-intensive:} There is a substantial captial and operational cost in running a large-scale infrastructure\cite{greenberg2008cost}, and which cause a sigificant reduction in the profit margins of the infrastructure owner\cite{isp-low-profit}. As a result, there is a relentless push for making infrastructure cost-effective to maximize profits. 
% might be better to just cite works on reducing cost in cloud computing.
Thus, cost reduction while meeting performance and other constraints is a central design problem that we address in this thesis. 

\textbf{Geo-distribued:} Such an infrastructure is often highly geo-distribtued, e.g., a large internet service provider (ISP) or a content delivery network (CDN) has Points-of-Presence (POP) at hundreds of locations \cite{dilley2002globally}. A key purpose of geo-distribution in infrastructure services is to maintain service deployment locations close to end-users. Thus, services must be designed to leverage geo-distributed resources for reducing user-perceived latencies.

\textbf{Locality-exhibiting workload:} Real-worlds workloads served by these infrastructures tend to exhibit significant geographic and temporal localities \cite{NCDN, youtubeUGC, vodP2Pbenefit, cellularvideotraffic}. Exploiting locality of demand to reduce infrastructure cost as well as user-perceived latencies is a key focus in our service designs.

\section{Degrees of freedom in infrastructure service design} Due to their geo-distributed deployment, these infrastructure services commonly make three sets of decisions: \emph{content placement}, \emph{request redirection}, and \emph{network routing}. As each of these decisions can be made relatively independently of others, we call them ``degrees of freedom'' available to a service. 
\begin{itemize}
	\item
	\textbf{Content placement} selects the locations at which a content is placed. Placement schemes seek to balance resource cost of keeping multiple content replicas with the benefits of improved availability and reduced user-perceived latency.
	\item
	 \textbf{Request redirection} selecs a location to send a content request to, with a preference for selecting a location that is nearby and has sufficient resources to service the request.
	\item
	 \textbf{Network routing} (or \textbf{traffic engineering}) selects the physical paths between nodes in the network for avoiding congestion hotspots in the network based on topoology and traffic demand patterns.
\end{itemize}


\section{Thesis statement}

\emph{Content placement is a more powerful factor that request redirection and network routing in determining the cost, performance and energy-related metrics for these services.}

\section{Why placement is more powerful than redirection, routing}
Content placement can achieve a good tradeoff between user -perceived latency and infrastructure cost due to geo-distribtued infrastructure and workload locality. Workload locality implies that a content is typically popular in only a few regions at any given time, and as a result only a few replicas of a content are sufficient to reduce user-perceived latency for most users. Further, the geo-distribued infrastructure enables these few replicas to be placed close to regions of demand, thereby reducing user-perceived latency as well as infrastructure cost. We illustrate with a couple of examples why placement can be a more powerful degree of freedom than redirection and routing in designing infrastructure services.


\begin{figure}
	
	\centering
	\includegraphics[scale=0.5]{fig/placement-vs-redirection.png}
	\caption{Placement vs. redirection: Content placement creates options for the redirection scheme to choose a nearby location for reducing user-perceived latencies.}	
	\label{fig:placement-redirection}
\end{figure}


\textbf{Placement vs. redirection:} Among the set of locations with the content, redirection chooses a location to send request. If the content is placed only at a far-away location, irrespective of how redirection is done, a user will observe a high latency to fetch content from the remote location. On the other hand, content placement can create more options to the redirection scheme to choose a location that is nearby. Thus, effective placement is a pre-requisite for a redirection scheme to provide low latencies.


%We briefly explain the \emph{traffic engineering} problem that is pertinent to our discussion of placement vs. routing. Traffic engineering computes network routing based on inputs of are the network topology, link capacities, and a \emph{traffic matrix}. A traffic engineering scheme computes routing to satisfy traffic demands while optimizing a cost function dependent on link utilization. For example, a common cost function is the maximum link utilization, MLU \cite{rexford}. 


\textbf{Placement vs. routing:} Content placement is more powerful than routing because it can change the \emph{traffic matrix} for which the routing is to be computed. A traffic matrix is a 2-dimensional matrix representing the demand in the network. The $i,j$-th entry in this matrix is the traffic from node $i$ to node $j$ in the network topology \cite{fortz2000internet}.  Let us take an example traffic matrix for which routing is to be computed (Figure \ref{fig:placement-routing}). Content placement can turn any non-zero traffic matrix into a null matrix (one whose all entries are zero) provided all content that a node in a network needs is placed at the same node. Such a placement obviates the need to send traffic to any other node, and therefore makes routing a trivial problem. While this is an extreme example, and one may not have sufficient resources to place content at all locations in the network, this example demonstrates that the ability to change the traffic matrix makes content placement more powerful than routing.

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{fig/placement-vs-routing.png}
	\caption{Placement vs. routing: content placement is more powerful than routing since it can change the  traffic matrix itself.}
	\label{fig:placement-routing}
\end{figure}


\section{Research overview}

The research in this thesis is categorized into three topics: 

(1) Traffic engineering is an important task for network operators and is responsible for cost and congestion reduction and fault tolerance \cite{rexford,COPE,TEXCP}. While traditionally traffic engineering is viewed as a routing problem, we study the role of content placement in shaping traffic engineering objectives in content-dominated networks.

(2) The lack of support for handling mobility in the Internet is well-documented \cite{HIP,LISP,HAIR,MobilityFirst}. Towards building infrastructure support for mobility in the Internet, we present the design and implementation of Auspice global naming service that meets the scalability and consistency requirements posed due to high mobility.

(3) To reduce the energy use of datacenters used for storing and serving content, we design and implement a system shrink that uses server consolidation and content migration to reduce energy use while meeting operator-specified service level agreements.


\subsection{Traffic engineering in content-dominated networks}

Traffic engineering in ISP networks is not isolated from decisions at the application layer.
The primary goal of traffic engineering is to configure network routing to reduce capacity provisiong costs as well as network congestion.
But, in a content dominated network, traffic engineering interacts with content placement and request redirection. The over-arching goal of our work is to design and evaluate ISP traffic engineering techniques while accounting for their interaction with content placement and request redirection. 

We address the above question in two scenarios. The first scenario in a more common occurence in present day Internet, in which an ISP has little control over placement and redirection. The second scenario is motivated by a recent, potentialy transformative trend: Network CDNs (NCDNs) -- CDNs deployed by ISPs on their infrastructures. Unlike traditional ISPs, an NCDN enjoys full control over placement, redirection and routing on its network.

\subsubsection{ISP network with content location diversity}

We model a content-dominated ISP network by accounting for its content \emph{location diversity} -- the presence of content at multiple network locations, and the ability of end-users to download content from those locations. Location diversity is enabled by several types of applications and services, such as CDNs, P2P, mirrored websites. We create location diversity using a simple content placement scheme -- randomly placing content at multiple locations --, to reflect the limited control of ISPs on content placement in their networks. 

%We further assume that users can download content in parallel from all locations. 

Our work presents an experimental comparison of several classes of traffic engineering schemes using data from real ISP topologies and traffic matrices. Our key findings are as follows: (1) We find that all traffic engineering schemes, including shortest-path routing, multiprotocol label switching routing, routing that is robust to unpredictable variations as well as optimal traffic engineering, achieve similar application performance and network capacity.   (2) We find that even a static shortest-path routing, or in other words a ``no'' traffic engineering  scheme is at most 30\% sub-optimal in terms of network capacity. Overall, these results suggest that even a limited placement flexibility reduces the value of sophisticated traffic enginering schemes, e.g., optimal traffic engineering, over simpler traffic engineering schemes, e.g., shortest path routing. These results are further strengthed in the case of a network CDN where the content placement flexibility is even greater.


\subsubsection{Network CDNs}

There are strong economic factors motivating ISPs to transform into network CDNs for delivering content to users on its network: falling bandwidth prices due to competition and technology trends, potential sources of revenue by selling content-based services to end-users, easy availability of CDN technology in the form of licensed and managed CDNs and reduction in backbone traffic due to content caching via NCDNs are some of the most prominent factors \cite{telco-cdn-arguments}. Today, more than 30 ISPs have deployed NCDNs. 

NCDNs represent a paradigm shift in which both content delivery and traffic engineering is handled by a single entity. 
A natural question is to ask how should NCDNs handle placement, redirection and routing for optimize traffic engineering objectives such as maximum link utilization, as well content delivery objectives such as user-perceived latency. Accordingly, our work evaluates several combinations of placement and routing schemes that an NCDN can deploy. First, a simple caching scheme for placement and a static-shortest path routing. Second, a joint optimization of placement and routing based on historic demand patterns. Third,  an ideal joint optimization with future knowledge of content demand.  Of particular interest to NCDNs are demand-oblivious schemes such as the first scheme, as they make placement and routing decisions without measurement of content demand and simplify network management for the operators.

Our key findings, based on real network topologies, and extensive traces from Akamai CDN, demonstrate the effectiveness of a demand-oblivious scheme. First, due to poor predictability of content demand and the churn in content workloads, a scheme that optimizes placement, redirection and routing jointly based on historical content demand performs much worse than the simple demand-oblivious scheme. Second, the demand-oblivious scheme performs close to an ideal joint-optimization strategy with knowledge of future content demand, largely because the caching scheme achieves high cache hit rates from caches placed inside the network.  Third, optimizing routing matters little in NCDNs: whether a static shorted-path routing or a routing optimized based on measured traffic demands is used along with a caching scheme, the network cost differs by less than 10\%. 


\textbf{Summary:} ISPs have traditionally focused on optimizing routing to achieve their objectives, but our research shows that in a content-dominated network, they are better served by leveraging placement flexibility using simple placement schemes.


\subsection{Global name service for highly mobile Internet}

The effects of Inernet's poor support for mobility are present everywhere:

Internet's poor support for mobility is visible at several corners: 

A key reason for Internet's poor support for moblity is that communication on the Internet is based on IP addresses that keep changing due to mobility. On the other hand, what remains unchanged is the name or identity of communication end-points. If we can enable communication over names, we can handle mobility. A  global name service (GNS) handle mobility maintaining an up-to-date mapping from names to network addresses for all names. If such a GNS were to exist, an end-point Alice would be able to establish a connection with another end-point Bob by querying the GNS for Bob's adresss as shown in Figure \ref{fig:gns-example}. 

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{fig/gns-example.png}
	\label{fig:gns-example}
	\caption{A global name service helps establish and maintain connections between mobile entities by keeping an up-to-date mapping from their names to their network addresses.}
\end{figure}

To appreciate the challenges in implementing such a GNS, we discuss the limitation of Internet's existing naming service DNS as a solution for mobility.
\begin{enumerate}
	\item DNS relies heavily on passive caching based on TTLs for reducing both system load and client-perceived latency. However, high mobility severely limits effectiveness of TTL-caching. Handling mobility requires up-to-date responses, so the load and client-perceived latency increase with the mobility rate irrespective of the TTL.
	\item Under high mobility, the latency to an authoritative name server determines client-perceived query latency in the common case. Today, authoritative name server locations are chosen statically irrespective of where the query demand is coming from, which could results in highly sub-optimal query latencies. 
	\item Due to DNS's hierarchical design, the implementation of DNSSEC extensions for DNS's security depends on a single root of trust, a root that is tightly controlled today by ICANN and the US Department of Commerce, a state-of-affairs that is inherently anti-competitive and geo-politically problematic. 
\end{enumerate}

Our work makes two main contributions towards addressing the challenges of designing a global name service for high mobility. 

\textbf{Global naming system:} We present a clean-slate naming system design that is incompatible with existing DNS but improves upon DNS's design in two aspects. First, it supports multiple roots of trust as a part of the naming system, thereby addressing the single root of trust problem in DNS. Second, it supports name-to-address resolution for arbitrary names unlike DNS, which restricts names to be hierarchical. In doing so, our naming system gives applications the full flexibility in choosing names. 

\textbf{Auspice name resolution service:} A key component of our naming system is Auspice: a scalable geo-distributed service for mapping names to network addresses under high mobility. A key decision in Auspice's design is that of placement of name records that store the name-to-address mapping. The placement problem is challenging due to a fundamental cost-vs.-performance trade-off: placing name record at multiple locations improves latency of content accesses but increases update propagation costs. To address this challenge, Auspice name resolution service infers pockets of high demand for a name and uses a heuristic placement strategy that selects both the number and location of the replicas in a demand-aware manner to provide low request latency, low update cost, and high availability.  We extensively evaluate Auspice for an expected workload of a global name service and show that it significantly outperforms both commercial managed DNS services as well as DHT-based replication alternatives to DNS. Auspice is deployable in the Internet today as a scalable managed DNS provider, potentially enhacing support for mobility in the present day Internet as well.

\subsection{Energy optimization in content datacenters}
Energy use is a key component of operational costs of \emph{content datacenters (CDCs)}, datacenters that are used for storing and serving content to end-users. CDCs can potentially reduce their energy use via consolidation of servers and switches, but in doing so, they risk inflating end-user response times potentially leading to SLA violations. Our primary contribution is to quantify the tradeoff between energy savings via consolidation and response times in CDCs, and the design and implementation of Shrink, a system that aggressively leverages this tradeoff in order to yield significant savings in energy use in CDCs while affecting user-perceived response times in a controlled manner. To our knowledge, Shrink is the first system to consolidate servers and switches in a coordinated manner, an approach that reduces network energy use by up to 42\% compared to network-unaware server consolidation schemes. Our evaluation of Shrink using a workload from a large CDN's datacenter shows that Shrink can reduce energy use by 35\% over a scheme provisioned for the peak demand, while increasing the mean, 95th and 99th percentile response times by 8\%, 3\% and 15\% respectively.



\section{Thesis organization}

The thesis is organized intro three parts in correspondence with the three topics of our research.

Chapter \ref{ch:te-background}, Chapter \ref{ch:beyondmlu} and Chapter \ref{ch:ncdn} present our research on traffic engineering in content-dominated networks. Chapter \ref{ch:te-background} presents background on traffic engineering, content delivery and the interaction between them. Chapter \ref{ch:beyondmlu} presents a comparison of traffic engineering schemes in a network with location diversity of content. Chapter \ref{ch:ncdn} designs and evaluates traffic engineering and content delivery schemes in a Network CDN.

Chapter \ref{ch:intro-auspice} presents the design, implementation and evaluation of a global name service for a highly mobile Internet.

Chapter \ref{ch:shrink} presents the design, implementaiton and evaluation of Shrink - a system for reducing energy use of content datacenters via server consolidation.

\section{Previous publications and collaboration}

\textbf{Chapter \ref{ch:beyondmlu}} revises a previous publication: A. Sharma, A. Mishra, V. Kumar, A. Venkataramani. Beyond MLU: An Application-Centric Comparison of Traffic Engineering Schemes. \emph{Proc. IEEE INFOCOM, April 2011}. Aditya Mishra and Vikas Kumar provided invaluable support in performing experiments for this work.

\textbf{Chapter \ref{ch:ncdn}} revises a previous publication: A. Sharma, A. Venkataramani, R. Sitaraman. Distributing Content Simplifies ISP Traffic Engineering. \emph{Proc. ACM SIGMETRICS, June 2013}. Ramesh Sitaraman provided access to Akamai datasets for this work. A realistic experimental evaluation would not have been possible without these datasets.

\textbf{Chapter \ref{ch:intro-auspice}} revises a previous publication: A. Sharma, X. Tie, H. Uppal, D. Westbrook, A. Venkataramani, A. Yadav. A Global Name Service for a Highly Mobile Internetwork. \emph{Proc. ACM SIGCOMM, August 2014}. 
This work also appears in Xiaozheng Tie's thesis, which describes the same placement algorithm and a simulation-based evaluation of the algorithm. The new material in this chapter includes (1) mechanisms to provide consistency of data and (2) experiments with an implementation of the placement algorithm in an emulation testbed and a geo-distributed testbed. Both Xiaozheng Tie and Hardeep Uppal have contributed to the placement algorithm. Hardeep Uppal, David Westbrook and Arun Venkataramani have contributed in implementing the \auspice\ system.

