%!TEX root = New.tex
\chapter{Introduction}
\label{ch:intro}

The Internet is adequate for providing connectivity between any two end-hosts across the globe, but is inadequate to provide the high-quality experience end-users  expect when interacting with web services today.  The reasons for the Internet's shortcomings are numerous. Long propagation delays that are fundamentally limited by the speed of light, transient and persistent congestion on network links, and sub-optimal path selection by the Internet routing protocols to name a few \cite{andersen2001resilient,DilleyMPPSW02,rahul2006overlays,Detour}.
%The Internet is a federation of thousands of networks, from large Internet service provider (ISP) networks, to smaller networks than span a single organization, e.g., a university campus. The federated structure of the Internet is adequate for providing connectivity between any two end-hosts on the Internet, but is inadequate to provide the high-quality experience end-users  expect when interacting with web services today.  The reasons for the Internet's shortcomings are numerous. Long propagation delays that are fundamentally limited by the speed of light, transient and persistent congestion on network links, and sub-optimal path selection by the Internet routing protocols to name a few.

The Internet's shortcomings are masked and high-quality user experiences are enabled by global networks of datacenters that form ``overlays'' on top of the Internet. Such an overlay network, commonly called a \emph{content delivery network} (CDN), uses algorithms for optimizing data transfer from the origin of the content to the end-user. These algorithms make several decisions to that end. First, they place content at locations close to end users \cite{DilleyMPPSW02}. Second, to serve each request the ``best'' server is selected whereby overloaded servers are avoided, and so are servers that are far away from  the end-user \cite{oasis}. Third, if default  paths in the Internet are performing poorly, then better alternate paths that are chosen that route traffic via nodes in the overlay network, an approach termed as \emph{overlay routing} \cite{andersen2001resilient}. 

The genesis of this thesis lies in the following question: 
\emph{what influence do the decisions at the overlay have on the routing strategies of the underlying network, and vice versa?}

This intriguing question is one of long-standing interest in computer science research  \cite{Roughgarden,selfishQiu,Jiang2009,JohariGameTheory, CATE, P4P}. 
Several related questions have been put forth. Does the interaction between network and content delivery yield sub-optimal results? How can we design cooperative mechanisms to leverage these interactions? Do cooperative mechanisms yield benefit in an Internet-like environment?
We find that nearly all previous research has focused either on the interaction of overlay routing with the network routing \cite{Roughgarden,selfishQiu}, or that of server selection strategies with the underlying routing  \cite{Jiang2009,JohariGameTheory, CATE, P4P}. 
Somewhat surprisingly, the role of placement strategies on this interaction has received little attention.  Nonetheless, content placement is an important factor in determining the performance and cost objectives of networks and content delivery systems as discussed below.


%3. A premise of thesis is that network's routing decisions and CDN's decisions at the application overlay interact with each other. The outcome of their respective optimizations depend on other's decisions.  e.g. interactions could increase the cost objectives of networks and CDNs, and interactions could worsen the user-perceived performance. 

\section{Placement affects networks and content delivery systems}

The role of placement strategies in improving performance and costs of content delivery is well known \cite{Saroiu2002}. Placement strategies commonly replicate content and in doing so, they increase availability of content, and reduce the latency between an end-user and the content. Replication improves user-perceived performance but increases costs, e.g., replicating a large video file increases the storage requirements \cite{Applegate2010}, and replicating dynamic objects increases the cost of propagating updates to all replicas \cite{volley}. Placement strategies used today achieve a good cost-performance tradeoff because they exploit the \emph{locality} inherent in real-world workloads  \cite{NCDN, youtubeUGC, vodP2Pbenefit, cellularvideotraffic}. Placement strategies exploit geographic and temporal locality patterns by replicating content at those times and and at those locations where the content is more popular, and thereby improve performance while minimizing replication costs.


We observe that placement strategies also play a role in influencing cost and performance of the underlying network. 
A major cost component of the network is the cost of \emph{provisioning capacity} on links in the network \cite{capacityplan}. 
If a placement strategy replicates content at multiple locations, it enables users to fetch content from nearby locations, thereby reducing the aggregate traffic in the network. This traffic reduction helps network operators cut capacity provisioning costs. 
To ensure good performance, network operators use \emph{traffic engineering} techniques \cite{fortz2000internet}, in which routes are  computed based on network topology and traffic demand patterns to avoid congestion hotspots.\footnote{We use the terms routing, network routing, and traffic engineering interchangeably.}   Placement strategies determine where content is available and therefore shape traffic demand patterns. Thus, placement strategies play an indirect role in  traffic engineering decisions, and affect network performance as well.

%We observe that placement strategies also play a role in influence cost and performance of the underlying network. If a placement strategy replicates content at multiple locations, it enables users to fetch content from nearby locations, thereby reducing the aggregate traffic in the network. This traffic reduction helps network operators cut  infrastructure costs of provisioning  capacity on network links.  As content placement shapes traffic demand patterns, it also influences how network operators configure the routing in the network.  Today, network operators adapt routing based on traffic demand patterns so that congestion hotspots do not occur, and network performance is superior. This process is known as \emph{traffic engineering}.\footnote{We use the terms routing, network routing, and traffic engineering interchangeably.}  By influencing how traffic engineering is done, placement strategies play a role in determining the network performance as well.


The observation that placement strategies influence objectives of both networks and content delivery raises several questions that form the motivation of this thesis. How does a given placement strategy, especially widely-used placement strategies, such as least recently used (LRU) caching, affect the objectives of networks and content delivery systems? Can we design new placement strategies that better serve objectives of both content delivery and  the underlying network? Finally, what is the relative important of content placement vs. other decisions, such as server selection and traffic engineering, in determining objectives of networks and content delivery systems.


\section{Thesis statement}
We state the thesis statement as follows: 
\begin{center}
\emph{Content placement is a powerful factor in shaping the network traffic and \\ simple placement strategies are effective in improving cost-, performance- and energy-related metrics for networks and content delivery systems.}
\end{center}
%evaluate the role of placement strategies on the objectives of networks and content delivery systems while accounting for the interaction between them.

\section{Research problems}

In defense of the above thesis, we investigate four research problems. We study the interaction between network and content delivery in following three scenarios focusing on the role of placement strategies: an Internet service provider (ISP) network in which content is placed at a small number of randomly chosen locations (Section \ref{sec:intro-beyondmlu} \&  Chapter  \ref{ch:beyondmlu}), an ISP that controls both the underlying network and content delivery on its network and therefore has full flexibility in designing placement strategies  (Section \ref{sec:intro-ncdn} \&  Chapter  \ref{ch:ncdn}), and a datacenter of a content delivery network (CDN) whose goal is energy-minimization, and makes both placement and routing decisions to that end (Section \ref{sec:intro-shrink} \&  Chapter  \ref{ch:shrink}). As most network traffic is generated by static content, such as video, audio and images \cite{cisco-videogrowth}, we study the interaction between network and content delivery assuming that content is static. 
The placement of dynamic content, the fourth problem in this thesis, is considered solely as a content delivery problem, unrelated to its interaction with the  network. We  design and implement a  placement strategy for dynamic content stored across geo-distributed datacenters (Section \ref{sec:intro-auspice} \&  Chapter  \ref{ch:auspice}). 

\subsection{Performance and cost optimization in Internet service providers}
\label{sec:intro-beyondmlu}

The first problem studies the interaction of ISP traffic engineering with a placement strategy that replicates content at a small number randomly chosen locations. We assume that end-users leverage replicated content by downloading in parallel from all locations.
We seek to understand how this interaction affects user-perceived metrics, such as file download time and Voice-over-IP (VoIP) call quality,  as well as a traffic engineering metric. 
We consider several classes of TE strategies, and networks with varying degrees of replication of content.
We conduct very large scale experiments simulating ISP traffic as a collection of TCP flows seeking to answer following questions:
\begin{itemize}
\item
How do TE strategies compare in terms of user-perceived performance metrics?
\item
What is the effective capacity of different TE strategies to tolerate surges in traffic demand?
\item
How much benefit does TE give over a simple static routing?
\end{itemize}

\subsection{Network CDN}
\label{sec:intro-ncdn}
A network CDN (NCDN) is an ISP that manages content delivery to users on its network. 
Unlike a traditional ISP (Section \ref{sec:intro-beyondmlu}) that control only the routing, an NCDN has flexibility of choosing the placement strategy as well.
We classify the possible NCDN strategies into \emph{planned strategies} whose decisions are based on historic content  demand patterns, and \emph{unplanned strategies} that are oblivious to historic content demand patterns.
We consider several strategies for an NCDN including a planned joint-optimization of placement and routing, an ideal planned strategy with perfect knowledge of future demand patterns, and a strategy that makes both placement and routing decisions in an unplanned manner.
We conduct trace-driven evaluations based on real ISP topologies and content access traces  from a leading commercial CDN, Akamai, to answer following questions:
\begin{itemize}
\item
How do simple, \unplanned\ strategies compare to the ideal planned strategy?
\item
How much benefit do joint optimization strategies yield over simpler strategies as practiced today, and does the benefit warrant the added complexity?  
\item
What is the relative importance of optimizing placement vs optimizing routing?
\end{itemize}



\subsection{Energy efficiency of CDN datacenters}
\label{sec:intro-shrink}
The third problem considers the design of an energy-efficient CDN datacenter while ensuring a minimal impact on user-perceived performance either due to cache misses or highly-loaded servers.
Our key insight is that jointly optimizing underlying network routing and application-level policies of load balancing and server shutdown can increase datacenter energy savings.
We are also exploring novel load balancing and server shutdown policies so that the resulting placement of content on servers ensures high cache hit rates and minimizes impact on user-perceived performance.  We plan to conduct trace-driven experiments with traces from a commercial CDN datacenter as well as experiments with a prototype to answer following questions:
\begin{itemize}
\item
What is the impact of energy-saving strategies on user-perceived performance? How do we design server shutdown and load balancing strategies to minimize this impact?
\item
How much additional energy savings can be obtain by a joint optimization of network and server energy?
\item
How do different types of content workloads, e.g, video, downloads, mixture of all traffic types, affect these results?
\end{itemize}

\subsection{Geo-distributed placement of dynamic content}
\label{sec:intro-auspice}

Several applications today generate dynamic content such as weather, stocks, status updates posted on social media websites \cite{volley, twitter}.
Placement of dynamic content is a challenging problem due to a fundamental cost-performance trade-off: dynamic content replication at multiple locations improves latency of content accesses but increases update propagation costs. 
State-of-art-systems either require manual placement configuration or use naive placement strategies, such as replicate-at-all-locations or   replicate-at-$k$-random-locations, incur excessively high update cost or sub-optimal latency \cite{spanner,beehive}. 

Our research problem is to design and implement a system that meets the following requirements.
(1) The placement of replicas should minimizes request latencies under pre-defined resource constraints across geo-distributed datacenters.
(2) The design should not pose a fundamental limitation either on the number of datacenter locations or the number of objects stored in the system.
(3) The system should provide flexible consistency semantics to meet requirements of wide-range of applications that need either strong or weak consistency semantics.

\section{Research approach}
We highlight the key elements of the approach we take to accomplish our research.

\textbf{Experimental methodology:} We take an empirical approach to evaluate our hypotheses, including experimentation with prototypes, and  packet- and flow-level simulations. 
The choice of the experimental methodology is dictated by the research problem in most cases. For example, experimenting with an actual NCDN infrastructure is beyond our resources, therefore our evaluation for that problem uses flow-level simulations (Chapter \ref{ch:ncdn}). 
In evaluating TE strategies based on user-perceived metrics (Chapter \ref{ch:beyondmlu}), we  perform packet-level simulations as they help us measure user-perceived metrics more accurately compared to flow-level simulations.

\textbf{Data collection:} We have performed extensive data collection from multiple ISPs including a Tier-1 US ISP, and from a leading commercial CDN, Akamai. From each ISP, we obtained point-of-presence-level (PoP-level) topology maps as well as PoP-to-PoP traffic demands represented in the form of traffic matrices. We have collected two sets of anonymized content access traces from Akamai CDN. The first set includes traffic for bit-intensive content such as video, and file downloads from users across the globe; these traces are used in evaluation of strategies for an NCDN. The second set of traces are collected at a single datacenter and include traffic of all content types; these traces will be used in evaluating the design of energy-efficient CDN datacenters. Our CDN traces contain logs of content accesses by millions of users, and reveal demand patterns at the level of individual objects, and therefore help us in evaluating placement strategies accurately.

\textbf{Evaluation metrics:} Our evaluation focuses on user-perceived performance metrics over system-level metrics, wherever possible. We find that a user-centric evaluation has potential to yield new insights. For example, Chapter \ref{ch:beyondmlu} shows that common traffic engineering strategies, yield near-identical user-perceived performance, while the same set of strategies differed by up to 2$\times$ on a system-level metric of maximum link utilization. Along the same lines, we plan to conduct evaluation of end-to-end download performance in our ongoing work on designing energy-efficient CDN datacenters.

%\section{Key findings}
%We highlights two key lessons that resonate from the results we are going to present in this thesis.
%
%\textbf{Simple heuristic placement strategies are effective.}
%1. Simple heuristic placement strategies are effective for CDNs: 
%Bad news: placement problems are NP-hard, there heuristics are necessary. Good news: simple heuristics peform well.
%LRU caching is highly effective due to geo-graphic and temporal locality. 
%
%\textbf{Placement matters more than routing.}
%2. Effective placement coupled with simple routing strategies are perform well

\section{Contributions}

This section presents a summary of contributions of this thesis. 

\begin{enumerate}
\item
We consider a placement strategy that replicas content at a small number of randomly chosen locations in an Internet service provider (ISP) network; end-users leverage the replicated content by downloading in parallel from all locations. 
Our experiments evaluate common traffic engineering strategies based on real topologies and traffic matrices. 
Our key contribution is to show that even a simple placement strategy that allows users to download content from just 2-4 locations enables all traffic engineering schemes to achieve near-optimal capacity to tolerate surges in traffic demand, and even simple static routing to be within 30\% of optimal. 
\item
We model a single entity that controls both network and content delivery as in the case of a network CDN (NCDN). 
We classify the possible NCDN strategies into \emph{planned strategies} whose decisions are based on historic content  demand patterns, and \emph{unplanned strategies} that are oblivious to historic content demand patterns.
Our experiments on real network topologies and traces from a large CDN surprisingly show that  unplanned placement strategies, e.g., LRU caching, combined with a simple static routing outperform (sometimes significantly)  realistic (i.e., history-based) joint-optimization strategies and can achieve network cost and user-perceived latencies close to those of a joint-optimal strategy with future knowledge. 
%\item
%We propose to study energy-minimizing schemes for a CDN datacenter seeking to establish that  significant energy savings are possible with minimal impact on user-perceived performance. Our preliminary results for a CDN datacenter serving on-demand video content show that (1) simple server shutdown and traffic engineering strategies yield close to optimal energy savings (2) energy-saving strategies cause less than 1\% decrease in cache hit rates while using a load balancing strategy similar to that used by CDNs today.
%We propose to study energy-minimizing schemes for networks seeking to establish that it is feasible to reduce energy consumption for NCDN and datacenter networks. Our central idea is that requests for content can be served by placing content on a subset of nodes during off-peak hours and if these nodes are carefully chosen, it enables large fraction of switches and links to be turned off with a minimal degradation in user-perceived performance. We present preliminary results from trace-driven experiments to support our hypothesis. 
\item
We design and implement  Auspice, a system for dynamic content replication across geo-distributed datacenters. Our system infers pockets of high demand for a name and uses a heuristic placement strategy to provide low request latency, low update cost, and high availability. 
An application suited for Auspice is a global name service to store name-to-address mapping of mobile devices. Our extensive evaluation for an expected workload of such a global name service on multiple testbeds shows that Auspice significantly outperforms both commercial managed DNS services as well as DHT-based replication alternatives to DNS. 
\end{enumerate}



\section{Organization}
Chapter \ref{ch:background} presents the main concepts used in this thesis -- traffic engineering techniques used by ISPs, algorithms used for content delivery including those for content placement and for request direction. This chapter also discusses prior work on the interaction between traffic engineering and content delivery. 

Chapter \ref{ch:beyondmlu}, Chapter \ref{ch:ncdn} and Chapter \ref{ch:auspice} present solutions and experimental results for the problems in Section \ref{sec:intro-beyondmlu}, Section \ref{sec:intro-ncdn} and  Section \ref{sec:intro-auspice} respectively. These chapters describe the research we have already completed towards this thesis. 

Chapter \ref{ch:shrink} surveys prior research on the design of energy efficient datacenters, and identifies key research questions that need to be answered in designing an energy-efficient CDN datacenter.

Chapter \ref{ch:proposed} presents a plan for future research to be accomplished towards the completion of this thesis.


%\section{How to read this thesis?}
%\begin{description}
%\item{\textbf{Background:}} The main concepts in this thesis -- traffic engineering techniques used by ISPs, algorithms used for content delivery including those for content placement and for request direction --- are presented in Chapter \ref{ch:background}. This chapter also discusses prior work on the interaction between traffic engineering and content delivery. 
%
%\item{\textbf{Completed work:}} 
%
%\item{\textbf{Proposed work:}} 
%
%\end{description}

\section{Previous publications and collaboration}

\textbf{Chapter \ref{ch:beyondmlu}} revises a previous publication: A. Sharma, A. Mishra, V. Kumar, A. Venkataramani. Beyond MLU: An Application-Centric Comparison of Traffic Engineering Schemes. \emph{Proc. IEEE INFOCOM, April 2011}. Aditya Mishra and Vikas Kumar provided invaluable support in performing experiments for this work.

\textbf{Chapter \ref{ch:ncdn}} revises a previous publication: A. Sharma, A. Venkataramani, R. Sitaraman. Distributing Content Simplifies ISP Traffic Engineering. \emph{Proc. ACM SIGMETRICS, June 2013}. Ramesh Sitaraman provided access to Akamai datasets for this work. A realistic experimental evaluation would not have been possible without these datasets.

\textbf{Chapter \ref{ch:auspice}} revises a previous publication: A. Sharma, X. Tie, H. Uppal, D. Westbrook, A. Venkataramani, A. Yadav. A Global Name Service for a Highly Mobile Internetwork. \emph{Proc. ACM SIGCOMM, August 2014}. 
This work also appears in Xiaozheng Tie's thesis, which describes the same placement algorithm and a simulation-based evaluation of the algorithm. The new material in this chapter includes (1) mechanisms to provide consistency of data and (2) experiments with an implementation of the placement algorithm in an emulation testbed and a geo-distributed testbed. Both Xiaozheng Tie and Hardeep Uppal have contributed to the placement algorithm. Hardeep Uppal, David Westbrook and Arun Venkataramani have contributed in implementing the \auspice\ system.

