%!TEX root = shrink.tex
\chapter{\shrink: Quantifying and Leveraging Energy-Performance Tradeoff in Content Datacenters}
\label{ch:shrink}

In today's content-dominated Internet \cite{cisco-videogrowth, nielsen-video-growth}, it is not surprising that many datacenters and Points-of-Presence (PoPs) are dedicated to storing and serving content to end users. We call these datacenters and PoPs {\em content datacenters} (or, \cdc s).

%Our consumption of digital content is increasing rapidly. The majority of the traffic on the Internet today is content, with video content by itself accounting for more than half the total traffic \cite{cisco-videogrowth, nielsen-video-growth}.  Not surprisingly, many datacenters  and  Points-of-Presence (PoPs) are dedicated to storing and serving content to end users. We call these datacenters and PoPs  {\em content datacenters} (or, \cdc s).

The increasing energy use of datacenters \cite{GreenbergCost, rasmussen2011determining, power-cost} has motivated a long line of research in \emph{consolidation} schemes that aggregate a datacenter's load on a fraction of components and save energy by turning off unused components \cite{chase2001managing, mathew12, rajamani2003evaluating, lin12}.
Consolidation exploits the over-provisioning of resources in a datacenter and the diurnal variations in load to potentially reduce datacenter energy use by up to 50\% \cite{mathew12}.


The practicality of consolidation as an energy-saving tool for a \cdc\ operator depends on its impact on end-user response time. End-user response time is a key metric on which  operators are evaluated \cite{comparingCDN}. Further, a sharp response time inflation may be perceived as service unavailability, thereby causing a service-level agreement (SLA) violation and revenue loss for an operator \cite{amazonSLA, microsoftSLA, hpSLA}. Despite a large body of literature on consolidation schemes, quantifying the precise impact on user-perceived response times is not well understood today.

Our position is that a lack of quantitative understanding of energy vs. response time tradeoff is potentially a major roadblock to widespread deployment of consolidation to reduce \cdc\ energy use. To provide the insights needed for an operator to reduce its energy use, we address these key questions: (1) What is the energy-response time tradeoff achieved by simple schemes for server and network consolidation in a \cdc\ that uses well-known schemes for load balancing and network routing? (2) What is the additional energy savings achieved by network-aware server consolidation over network-unaware server consolidation considered previously?

Our primary contribution is to quantify the tradeoff between energy savings via consolidation and response times for a real \cdc's workload, and the design and implementation of a system, \shrink, to leverage this tradeoff. \shrink\ reduces the energy use of servers and switches via consolidation, while enabling operators to achieve the desired response time and hardware reliability. A novel aspect of \shrink\ is a network-aware server consolidation scheme that selects the active servers in a left-to-right order in a topology and achieves greater network energy savings over network-unaware server consolidation schemes. Further, our server and network consolidation schemes require only ECMP (equal-cost multipath) support for routing, and hence, are deployable with existing datacenter network fabrics.

Our work is grounded in implementation, due to which it accounts for several factors affecting response time - increased load on servers and network links, reduced storage and its impact on cache hit rates, non-steady state cache behavior due to on-off transitions, imperfect load balancing among servers - and hence, accurately quantifies the impact of consolidation on end-user response time. A key insight, supported via experiments, is that cache hit rates, despite server consolidation, remain close to an unconsolidated datacenter. A small reduction in hit rates helps mitigate the impact of consolidation on response times. This finding is explained by the skewed content popularity obseved in real workloads, due to which working set size of content remains small compared to the storage available in a CDC.

%a simple placement strategy LRU caching achieves a cache hit rate near to an unconsolidated datacenter. 


%A key insight we leverage is that due to skew in the content popularity  commonly observed is real content workloads cache hit rates are minimally affected despite consolidation. A simple LRU caching scheme achieves a cache hit rate near to an unconsolidated datacenter.
%, and substantiate via experiments, 


%\shrink\ uses some well-known ideas, namely, randomization for load balancing and ECMP (equal-cost multipath) for routing; their use is in line with our goal of quantifying the energy-response time tradeoff for load balancing and routing schemes that we expect to be widely used in \cdc s. 

% -- and hence, accurately quantifies the impact of consolidation on response time due to consolidation.

% to accurately model the relation between server utilization and response time, impact of server consolidation on cache hit rates, and non-ideal load balancing. For these reasons,  our work provides an accurate characterization of energy-response time tradeoffs for \cdc s.




%A challenge \cdc\ operators face is to reduce their energy use with meeting service-level agreements (SLAs) dependent on end-user response times. Energy is a major factor in the operational costs of a datacenter \cite{barroso2007case}  and contributes to 15-20\% of total cost of ownership of a datacenter \cite{GreenbergCost,rasmussen2011determining,power-cost}. A promising approach for reducing datacenter energy is \emph{consolidation}, in which the load on the datacenter is aggregated on a fraction of components, which enables the remaining components to be turned off for saving energy. But, in the context of a \cdc, consolidation can potentially inflate end-user response times by increasing the load on servers and switches that are active and increasing the cache miss rates.  As an inflation in response times could incur violations of a \cdc's SLAs, the practicality of energy saving by consolidation for \cdc s (and other datacenters also) cannot be evaluated without accurately quantifying the impact of those schemes on end-user response times.


%Our work makes two other contributions. First, we propose a network-aware server consolidation scheme that selects the active servers in a left-to-right order in a topology and increases the potential network energy savings.  Second, we present a simple model, which shows that energy vs. response time tradeoff is more favorable as the skew in the server's utilization vs. delay profile increases and the skew in the content popularity distribution increases.

%Second, we present a simple model of energy use and response time in \cdc s, which shows that energy savings can be achieved with a small response time inflation for Zipf content workloads, provided server queuing delay remains a small fraction of the response time even at a high server utilization. Our analysis also shows that the energy-response time tradeoff improves as the skew in the content popularity increases.

We have built a prototype of \shrink\ using Squid \cite{squid}, a caching proxy, and have deployed it on Amazon EC2 \cite{ec2} and Emulab \cite{emulab}. To conduct a realistic evaluation, we have collected and used traces containing more than 2 billion requests generating nearly 200 TB of traffic from a datacenter of the world's largest CDN, Akamai. Our key empirical results are the following. 

(1) \emph{Comparison to baseline:}  \shrink\ reduces energy use by 35\% over a baseline scheme that provisions resources according to the peak demand while increasing mean, 95-th \%-ile and 99-th \%-ile latency by 8\%, 3\% and 15\% respectively. 

(2) \emph{Comparison to ideal:}  \shrink\ achieves a mean, 95-th \%-ile and 99-th \%-ile response time that is 15\%, 3\% and 25\% higher than a scheme that characterizes the ideal energy-response time tradeoff while using 5\% more energy than it.

(3) \emph{Comparison of network energy use:} When one-fourth of the servers are active, \shrink's network energy use is lower than a network-unaware server consolidation scheme by 37\% and 42\% on FatTree \cite{fattree} and VL2 \cite{vl2} respectively.

\textbf{Scope of the paper:} This paper focuses on energy saving schemes based on server and network consolidation deployable at the scale of a single \cdc. The following schemes, although related, are outside the scope of this paper: (1) Adapting global load balancing across \cdc s to reduce the total energy use of all \cdc s. (2) Making each server or switch power-proportional, e.g., server energy use can be reduced by turning off a fraction of its disks. (3) Optimizing the cost of energy used such as by accounting for time-of-day pricing for electricity; Section \ref{sec:discussion} discusses electricity costs.



%A classic technique for saving energy is {\em consolidation} where server and network components can be turned off during periods of low load. In principle, this is a good approach since deployed systems are always over-provisioned to serve the peak load. In fact, there has been much work on server consolidation \cite{lin2011dynamic,mathew12} and some work on network consolidation \cite{Abts2010} that turn off servers and switches respectively to save energy.  Server consolidation schemes reduce energy use by aggregating demand on a subset of servers based on datacenter load. As servers are typically lightly loaded in off-peak hours, server consolidation has been shown to reduce energy use by up to 50\% \cite{mathew12}. A datacenter can further reduce its energy use by turning off a fraction of its switches, which is shown to use 10-20\% of overall energy \cite{Abts2010}. 
%It is viable for \cdc s to use 


% scheme-scaled 
