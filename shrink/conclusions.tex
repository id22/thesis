%!TEX root = shrink.tex
\section{Conclusions}


Despite much prior work on reducing the energy use of datacenters via server and network consolidation, a major barrier to their widespread adoption today is that operators worry deeply about the impact on SLAs or user-perceived response times, but the precise relationship between energy savings and response times is not well understood. Our work takes a step towards addressing this concern by presenting a model to quantify the energy savings vs. response time inflation trade-off in \cdc s. Based on these insights, we have designed and implemented \shrink, a system that leverages this tradeoff to yield significant energy savings while affecting user-perceived response times in a controlled manner. Shrink's novel network-aware server consolidation algorithm reduces network energy use by up to 42\% compared to network-unaware server consolidation schemes. Our experiments based on content access traces from an Akamai datacenter showed that our energy optimization algorithms reduce energy use by 35\% compared to a conservative baseline scheme that provisions servers as per the peak demand while increasing mean response time by 8\% over it. Overall, our findings encourage deployment of energy optimization techniques  in \cdc s.
%Despite much work on reducing the energy use of datacenters via server and network consolidation, a lack of quantitative understanding of energy vs. response time tradeoff is potentially a major roadblock to widespread deployment of energy saving schemes in \cdc s. Our work addressed this concern by quantifying the tradeoff between end-user response time impact and energy savings in \cdc s, and presented the design and implementation of \shrink, a system that leverages this tradeoff to yield significant energy savings while affecting user-perceived response times in a controlled manner. Shrink's novel network-aware server consolidation algorithm reduces network energy use by up to 42\% compared to network-unaware server consolidation schemes. Our experiments based on content access traces from an Akamai datacenter showed that our energy optimization algorithms reduce energy use by 35\% compared to a conservative baseline scheme that provisions servers as per the peak demand while increasing mean response time by 8\% over it. Overall, our findings encourage deployment of energy optimization techniques  in \cdc s.


%We also studied the interaction between load balancing policies and server energy optimization in a \cdc\ and showed that a simple random load balancing policy is effective in avoiding load hotspots and results in a small impact on cache hit rates even as energy optimization algorithms vary the set of active servers in a \cdc. 

%Further, we designed novel  algorithms that select the set of active servers and switches in a ``network-aware'' manner to provide additional network energy savings. 
