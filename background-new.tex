\chapter{Traffic engineering in content-dominated networks: background and motivation}
\label{ch:te-background}

This chapter serves two main purposes. First is to provide the reader with necessary background on ISP traffic engineering, content delivery and the interaction between them (Section \ref{sec:bg-bg}). Second is to explain the motivation for our work on traffic engineering in content-dominated networks in light of the existing work in this area (Section \ref{sec:bg-motivation}).




In comparison, following are the main new research directions that we pursue in this thesis. We explain each of them further in the chapter.

\begin{itemize}
	\item
	How do ISP traffic engineering schemes compare in terms of application-performance metrics such as TCP download time? Further, how do they compare while accounting fo r the effect of  application adaptation? 
	\item
	How should network CDNs--an ISP that operates a CDN on its infrastructure to deliver content to users on its network--perform content delivery given that they control both the content delivery and the underlying network routing?
	\item
	What role does content placement influence the interaction between network and content delivery, and what its its effect on user-perceived performance and netowrk cost?
\end{itemize}


%Traffic engineering done by Internet service providers focuses on  computing the routing in the network for optimizing cost and other objectives. But, traffic engineering techniques are not isolated from mechanisms that alter the flow of traffic from the application. In particular, decisions at the application-layer ``overlay networks'' such as content placement and redirection also seek to alter how traffic flows in the network. Motivated by this observation, a question of long standing interest has been the following: 

%\emph{what influence do the decisions at the overlay have on the routing strategies of the underlying network, and vice versa?} 



%Internet is composed of independently controlled sub-networks called autonomous systems. an isp is one such autonomous system. an isp does traffic engineering to configure routing. in a content-dominated network, application-level decisions on content placement and request redirection affect traffic engineering. the high goal of this part of this thesis is to design and to evaluate traffic engineering schemes while accounting for the interaction with content delivery decisions. the focus on evaluating the role of content placement  while studying this interaction distinguishes us from prior work in this area.

%This chapter provides background on content delivery and traffic engineering and makes a case for studying the role of content placement on this interaction. Chapter x and Chapter y studies traffic engineering in two scenarios with varying degrees of flexiblity in placing content. Chapter x focuses on an ISP network in a fixed content placement policy, namely that of placing content at multiple locations chosen randomly. While, Chapter y focuses on a network CDN, an ISP that deploys a CDN to deliver content to users on its network and enjoys full freedom to control the placement and routing on its network. 

\section{Background}
\label{sec:bg-bg}
Our review of prior work provides following main findings:



\begin{itemize}
	\item
	ISP traffic engineering is studied mostly as an optimization problem for minimizing link-utilization based cost functions (Section \ref{sec:ch2-te}).
	\item
	Content delivery networks (CDNs) commonly use \emph{demand-oblivious} techniques for content placement and request redirection towards improving user-perceived performance across the Internet (Section \ref{sec:ch2-cdn}).
	\item
	Interaction between traffic engineering and content delivery has been shown to affects user-perceived performance as well as network cost. But, prior work has focused mostly on the interaction of traffic engineering with either overlay routing or with request redirection (Section \ref{sec:ch2-te-cdn}).
\end{itemize}


\subsection{Traffic engineering}
\label{sec:ch2-te}

The goal of traffic engineering (TE)  is to avoid congestion hotspots in the network by optimizing routes based on network topology and expected traffic demand. In the context of large Internet service provider (ISP) networks, traffic engineering decides both intra-domain (within the ISP) and inter-domain routing (across ISPs). We focus here on intra-domain routing and refer the reader to  \cite{Feamster2003,rexford} for a survey of inter-domain traffic engineering. 

The evaluation metric for traffic engineering is a cost function that is dependent on the utilization of network links. Link utilization is a relevant metric because a low utilization of all links implies that the network is free from congestion hotspots and has spare capacity to tolerate an increase in demand. A well-known cost function is maximum link utilization or MLU. We give a simple example to show how traffic engineering can reduce link utilization.


We classify traffic engineering approaches into three groups:
\begin{description}
	\item[Optimal] If the traffic matrix is known accurately, the optimal solution to the traffic engineering problem can formulated as a multi-commodity flow optimization problem. The routing thus computed is reffered to as \textbf{Optimal} traffic engineering in literature.
	\item[Demand-aware] As it is impossible to have accurate knowledge of future traffic matrices, a demand-aware  traffic engineering  periodically updates routing using historically observed traffic matrices.
	\item[Demand-oblivious] A demand-oblivious  traffic engineering  requires no explicit measurement of traffic matices, but instead configures routing statically. A demand-oblivious  traffic engineering  is simpler to implement because it requires neither measuremnt nor periodic updating of network routing. 
	
\end{description}


%As it is impossible to have accurately knowledge of future traffic matrices. Therefore, practical traffic engineering schemes either take a demand-aware or a demand-oblivious approach.  A demand-aware  traffic engineering  periodically updates routing using historically observed traffic matrices. A demand-oblivious  traffic engineering  requires no explicit measurement of traffic matices, but instead configures routing statically. A demand-oblivious  traffic engineering  is simpler to implement because it requires neither measuremnt nor periodic updating of network routing. But, demand-aware schemes have been shown to outperform demand-oblivious  traffic engineering.

In practice, demand-aware traffic engineering based on Open Shortest Path First (OSPF) and Multiprotocol Label Switching (MPLS) are commonly used  \cite{COPE,MultiTM,fortz2000internet,MPLS2}. Routes computed by OSPF traffic engineering must follow shortest-weight paths, therefore OSPF TE provides limited functionality to split traffic among multiple paths. MPLS TE overcomes this limitation by enabling traffic between two nodes to be split  in arbitrary ratios among multiple paths. Therefore, MPLS TE gives better results than OSPF TE as exemplified by the above example \cite{COPE,MultiTM}.

%Therefore, TE schemes commonly take a demand-aware approach, i.e., they compute routing using historically observed traffic matrices. In contrast, demand-oblivious simpler schemes also exist, no measurement of traffic matrix or continual updating of configuration. 

%But, future demand is not known perfectly. So, TE schemes commonly take a demand-aware approach: use historic demand patterns to predict future demand. In contrast, demand-oblivious simpler schemes also exist, no measurement of traffic matrix or continual updating of configuration. Demand-oblivious is simpler but demand-aware schemes have been shown to outperform them in TE literatue.

%
%Cost-based metrics: ignored the impact on end-user performance. So, what is the impact on end-user performance.
%
%TE is isolation, ignoring the internation with content placement and redirection.
%
%How do TE schemes compare when accounting for the interaction with content delivery.


\subsection{Content delivery}
\label{sec:ch2-cdn}

Content delivery systems seek to provide a high-quality experience to users accessing content in all regions  at all times. A canonical example of a content delivery system is a content delivery network (CDN). State-of-the-art CDNs operate geo-distributed datacenters, and use a combination of edge caching, intelligent server selection, and path and protocol optimizations for delivery of several types of content, e.g., video, bulk downloads, and interactive websites \cite{DilleyMPPSW02,akamai-overview}. Given their geo-distributed deployment, the decisions of content placement, i.e., locations at which a content is placed, and request redirection, i.e., which location is best positioned to serve a user's request, are central to the functioning of a CDN.

\textbf{Content placement:} Content placement in CDNs is commonly done using caching schemes. For example a commonly used caching strategy is least recently used (LRU) cache replacement. There are two reason why content cahing is widely used. First, caching naturally captures geographic and temporal locality in content requests to populate caches with content likely to be reused. Second, a vast majority of network traffic is generated by content that gets updated infrequently, e.g., a video, audio, images. As a result, cached copies of content remain reusable for long duration. 

%Strong consistency is a separate topic and is studied in the content of design of geo-distrbuted kv store in auspice.\tbd{fix this}

\textbf{Request redirection:} Request redirection strategies complement placement strategies by selecting the server location that is best suited to process a user's request. These strategies have been extensively studied and form the heart of CDN technology today. To quote from a report by Akamai,  \emph{``the system directs client requests to the nearest available server likely to have the requested content."} where the ``nearest" server is one whose round trip latency as well as packet losses are small, and  an ``available" server is one that is lightly loaded considering all resources, i.e., network, CPU and disk  \cite{DilleyMPPSW02}. 

Request redirection is implemented using three processes: (1) \emph{Monitoring:} Probe messages sent intermittently help monitor network characteristics and server load and identify congested regions of network and overloaded server locations \cite{oasis,donar}. (2) \emph{Estimating distances:} The measured statistics are combined to compute a distance function that reflects the proximity of a server location to users in a geographic region \cite{donar}. (3) \emph{Informing the user:} The user is informed of selected server/s either via DNS resolution or via HTTP redirection as described in  \cite{DilleyMPPSW02} and  \cite{barbir2003known}.


Similar to our classification of traffic engineering schemes, we consider common content delivery techniques discussed above to be demand-oblivious since they do not require explicit measurement of content demand. In contrast, a demand-aware approach to content placement and redirection has also been studied, e.g., Applegate \emph{et al.} use a demand-aware approach to determine placement and redirection for Video-on-Demand content in the network. 

\subsection{Interaction between traffic engineering and content delivery}
\label{sec:ch2-te-cdn}

Content delivery routes traffic at the application layer using an overlay network of servers, and traffic enginering configures network routing of the underlying physical paths. Studying this interaction between decisions at the overlay and the underlying network has been a topic of long standing interest in computer science. Several related questions have been put forth. Does the interaction between network routing and content delivery yield sub-optimal results? How can we design cooperative mechanisms to leverage these interactions? Do cooperative mechanisms yield benefit in an Internet-like environment? We find that nearly all previous research on this topic has focused either on the interaction of overlay routing with the network routing \cite{Roughgarden,selfishQiu}, or that of server selection strategies with the underlying routing  \cite{Jiang2009,JohariGameTheory, CATE, P4P} as discussed below. 

%Studying the interaction between network and content delivery has been a topic of much interest in both systems and theory communities. Several related questions have been put forth. Do these interactions negatively affect objectives of networks and content delivery systems? What is the sub-optimality caused due to these interactions in the worst case, and for typical topologies and traffic demands? How to leverage these interactions to improve traffic engineering and content delivery objectives? 

%Yet, we don't fully understand these interactions because prior research has studied the interaction of network routing with only a subset of content delivery decisions. Much prior research has focused on two aspects: the interaction of overlay routing and network routing  \cite{Roughgarden,selfishQiu}, and the interaction of request redirection and network routing  \cite{Jiang2009,JohariGameTheory, CATE, P4P}. While placement decisions are critical to user-perceived performance, there has been little research on how content placement interacts with network routing.

\textbf{Interaction between traffic engineering and overlay routing:} Several results show the negative interaction between selfish overlay routing and network routing \cite{Roughgarden,selfishQiu}. Theoretical results indicate that the negative interaction could cause an arbitrary degradation in user perceived delay. Further studies using synthetic traffic demands and topologies indicate that this interaction hurt traffic engineering metrics. However, it appears that a small fraction of Internet traffic uses overlay routing.  For example, traffic from CDN edge server to the client always follows network routing. Further, overlay routing yields ``marginal" benefits ($<$ 30\%) over network routing for 79\%-96\% of paths depending on which geographic region is being considered  \cite{rahul2006overlays}, which suggests that traffic between CDN servers forming an overlay network follows network routing in most cases. For this reason, this thesis does not model the interaction between overlay and network routing.

\textbf{Interaction between traffic engineering and request redirection:} Recent research has investigated the interaction between request redirection and traffic engineering, without considering the role of placement strategies. This interaction is commonly studied in the context of Internet service providers (ISPs) and content providers (CPs) with geo-distributed datacenters. 
Both analytical results \cite{Jiang2009,JohariGameTheory} and system implementations \cite{CATE,P4P} have shown that there is value for joint optimization of request redirection and traffic engineering, and cooperative strategies can help traffic engineering metrics and also reduce user-perceived latencies. Commonly, these efforts assume that all content is available at all locations, ignoring the fact that content availability at a location depend on placement strategies. Therefore, in this thesis, we account for the effect of content placement along with request redirection, in studying the interaction between network and content delivery.


\section{Motivation}
\label{sec:bg-motivation}

The following key points summarize our motivation for studying traffic engineering in content-dominated netowrks.
\begin{itemize}
	\item
	Are link-utilization based metrics may good predictors of application performance that depends on other factors such as propagation delay, access and backbone link capacity, etc? Further, are these metrics are also poor predictors of capacity in scenarios when applications can download content from multiple locations?
	\item
	Since content placement can be a more powerful factor in reducing network cost, can content placement flexibility obviate the need for sophisticated traffic engineering?
	\item
	Network CDNs can control placement, redirection and routing on their network. Should they make these decisions independently or jointly? Further, should they use a demand-aware or a demand-oblivious approach to make these decisions?
\end{itemize}
%First, link-utilization based metrics may not be good predictors of application performance that depends on other factors such as queuing delay, access and backbone link capacity, etc. 
%Second, most work considers traffic engineering in isolation ignoring its interaction with content delivery, and even work 
%that accounts for this interaction has not focused on the role of placement strategies.
%Third, the problem of managing a network CDN in which a single entity handles both content delivery and traffic engineering has not been considered before.


\subsection{Do link-utilization based metrics reflect application performance and network capacity?}


Link-utilization based metrics may not be a good predictor of application performance.
Link-utilization primarily affects network quueing delay and loss. 
Application performance depends on other factors such as propagtion delay, access and backbone link capacity as well.
Queuing-theoretic models show that a high link utilization adversely affect queuing delay only at high utilization levels. For low to moderate utilization levels that are common in today's network, a reduction in link utilization may not yield a commensurate benefit in application peformance. 

\begin{figure}[tbh]
	\centering
	\label{fig:3node-bg}\includegraphics[scale=0.5]{final_images/Diagram3node.png}
	\caption{Lasso network}
\end{figure}

Link-utilization based metrics may not be a good predictor of network capacity in scenarios where applications have the ability to download content from mulitple locations. In Figure~\ref{fig:3node-bg}, all links are assumed to have a capacity of 100 units and a constant delay. The top link A has a very small delay compared to the other two links that both have equal delay. Node 1 has 100 Mbps of demand that it can obtain from 2 as well as 3. In addition, there is 20 Mbps of demand at node 1 which it can obtain only from 2.  We assume that the aggregate demand at a node consists of a large number of user-initiated connections. When content can be downloaded from multiple locations, users initiate parallel TCP connections and the throughputs along paths in a parallel TCP connection are inversely proportional to the path delays. The TE scheme is assumed to be OSPF-based, i.e., shortest-path routing using configured link weights and traffic split equally among multiple paths with equal weights.

%\textbf{point: TE cannot be achieved since adaptation changes TM.}

Suppose the weights of the links A and B are unequal and the link A has more weight. As a result, all of the traffic between 1 and 2 is routed using only link B. 1 splits its demand of 100 Mbps using parallel TCP equally between links B and C. Thus, the traffic on links A, B, and C is  0, 70, and 50 respectively. In the next step, seeking to balance load better for this resultant matrix, the TE scheme sets both the links A and B to the same weight (hoping to achieve link utilizations of 35, 35, and 50 respectively).  Consider how parallel TCP connections respond to this change.
Assuming each TCP connection between 1--2 is pinned to only one of the two paths---as is commonly done in practice to achieve equal-cost multi-path (ECMP) splitting---50 Mbps of demand at 1 gets routed using parallel TCP connections over the link A and link C, and an equal amount using parallel TCP connections along the link B and link C. In addition, the 20 Mbps of background traffic is split equally among link A and link B as per ECMP.  Since link A has a much smaller delay than link C, the 50 Mbps of demand at 1 using parallel TCP along those two paths will flow entirely through link A. The remaining 50 Mbps using B and link C will get split equally across the two paths by parallel TCP. Thus, the traffic on the links A, B and C is 60, 35, and 25 respectively, which is different from what the TE scheme engineered for (namely, 35, 35, and 50). The resulting MLU of 0.6 is different compared to 0.5, the value that the TE scheme expected. 



%The following two observations motivate us to revisit ISP traffic engineering:
%\begin{itemize}
%	\item
%	The use of link-utilization based metrics may not be a good predictor of application performance that depends on other factors such as queuing delay, access and backbone link capacity, etc. 
%	\item
%	Traffic matrices form the basis of evaluating traffic engineering schemes, but application-level adaptation can change these traffic matrices itself in response to an updated routing.
%\end{itemize}

%The new direction we pursue is to shift focus from link-utxilzation based metrics to application-level metrics such as TCP file download times, and to account for the effect of application-level adaptation in evaluating traffic engineering schemes. In Chapter \ref{ch:beyondmlu}, we provide a comparison of traffic engineering schemes focusing on user-perceived metrics such as file download times, and VoIP call quality. In Chapter \ref{ch:beyondmlu} and Chapter \ref{ch:ncdn}, we evaluate TE schemes while accounting for the effect of application-level adaptation and show that this interaction helps simpler TE schemes, such as oblivious TE or OSPF TE, perform closer to the optimal TE strategy in terms of user-perceived metrics as well as TE metrics.

\subsection{Does content placement flexibility obviate sophisticated traffic engineering?}


\textbf{Example 2: Demand-aware content placement} To appreciate how placement can shape traffic, consider the simple example in Figure~\ref{fig:NetworkExample}. Node $C$ has an object in its cache that is requested by end-users at nodes $A$ and $D$. Suppose that one unit of traffic needs to be routed from $C$ to $A$ and $0.5$ units  from $C$ to $D$ to satisfy the demand for that object. The routing that achieves the minimum MLU of $0.5$ to serve the demanded object is shown in the figure. Note that the routing that achieves the MLU of 0.5 is not possible with a simple, \unplanned\ protocol like InverseCap as that would route all the traffic demand from $C$ to $A$ via $B$, resulting in an MLU of 1. Thus, a (\planned) traffic engineering scheme is necessary to achieve an MLU of 0.5.


\begin{figure}[h]
	\centering
	\includegraphics[width=2in]{ncdnpaper/ncdn-example}
	\caption{A simple \ncp\ example}
	\vspace{-.3in}
	\label{fig:NetworkExample}
\end{figure}


On the other hand, NCDNs can shape the traffic demand matrix by using a judicious placement and redirection strategy. Suppose that there is some space left in the content server's cache at node $B$ to accommodate an additional copy of the demanded object. By creating an additional copy of the object at $B$, the traffic demand of $A$ can be satisfied from $B$ and the demand of $D$ from $C$ achieving an MLU of $0.125$. In this case, judicious content placement decreased the MLU by a factor of $4$. Even more interestingly, this best MLU can be achieved using a simple routing scheme like InverseCap while also improving user-perceived latency (assuming that the latency of link $BA$ is lower than that of the two-hop paths from $C$ to $A$).

In this example, content placement flexibility reduces network cost and enables simpler routing. But, what happens for real content and traffic traces? How effective are simple placement schemes towards optimizing user-perceived performance and network cost?

% As earlier examples show, content placement can be a more powerful degree of freedom than request redirection and network routing. 

% What is the relative importance of placement vs routing? Can content placement obviate the need for sophisticated traffic engineering schemes?




\subsection{Do Network CDNs need joint optimization of content delivery and traffic engineering?}



\textbf{How well do simple demand oblivous compare against demand-aware?}

\textbf{An NCDN can potentially jointly optimize content delivery and traffic engineeing, but do such sophisticated schemes yield benefits from a CDN?}



A Network CDN (NCDN) is an ISP than owns and operates a CDN over its infrastructures to deliver content to its end users. As NCDNs manage both the underlying network and content delivey, the objectives and the techniques available to a network CDNs are not the same from a traditional ISP or a tradidional CDN. Our work is motivated by the following questions:

\begin{itemize}
	\item 
	Is a demand-aware or a demand-oblivious content delivery and traffic engineering scheme more effective for a network CDN?
	\item
	An NCDN can potentially jointly optimize content delivery and traffic engineeing, but do such sophisticated schemes yield benefits from a CDN?
\end{itemize}

To our knowledge, this thesis presents the first study of techniques for a managing a NCDN based on real network topology and content access traces. Our result show the effectiveness of simple demand-oblivious schemes for content delivery and traffic engineering in achieving performance close to an ideal scheme. Further, they show that a demand-aware joint optimization performs poorly due to frequnt churn in content workloads and change in access patterns. 





\eat{
\section{Illustrating the interaction between content placement and traffic engineering}

We make a case for studying the interaction between content placement and traffic engineering by illustrating that content placement can change the traffic matrix. The first example shows that if content is placed at multiple fixed locations in the network, then merely updating network routes can change the traffic matrix. The second example shows that if content placement can be changed, it can change the traffic matrix in way that reduces network cost and enables simpler routing in the network.



\section{Research questions}

The above examples make a case for modeling the effect of content placement while studying the interaction between traffic engineeering and content delivery. Consequently, our work accounts for the interaction between placement, redirection and routing while addressing the following key questions: 

(1) How do well-known classes of traffic engineering schemes compare in terms of available capacity and end-user performance metrics?

(2) What is the relative importance of placement and routing for optimizng performance and cost objectives?

(3) If a network can control content delivery as well underlying routing, should that network follow simple demand-oblivious schemes for content placement and routing, or a more sophisticated scheme that jointly optimize these two decisions?

}


