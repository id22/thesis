%!TEX root = Main.tex
\section{Evaluation}
\label{sec:eval}

Our evaluation seeks to answer the following questions: (1) How well does \auspice's design meet its performance, cost, and availability goals compared to state-of-the-art alternatives under high mobility? (2) Can \auspice\ serve as a complete, end-to-end solution for mobility and enable novel communication abstractions? (3) How does \auspice's cost-performance tradeoff compare to best-of-breed managed DNS services for today's (hardly mobile) domain name workloads?

%Our main goal is to quantify the benefits and costs of the choices in \auspice's distributed design---our main contribution---with respect to the subset of design goals  (Section \ref{sec:design_goals}) that are quantifiable, namely client-perceived latency benefit and provider-perceived update cost under high mobility. We use the implemented prototype to evaluate (1) \auspice's replication strategies against simple ones used by DNS providers today as well as DHT-based alternatives proposed in research, and (2) a deployment of \auspice\ against several commercial managed DNS providers in live operation. We use simulations to evaluate (3) the sensitivity of \auspice's benefits with respect to mobile workload parameters, and (4) the scalability of \auspice\ to regimes beyond those permitted by our testbeds. We do not attempt to evaluate \auspice's functional design goals---resilience to failures, consistency, extensibility, security---except to the extent that all experiments subsume the overhead of these features.

\eat{Our main results are:

\begin{itemize}
\item
\emph{Lookup latency:} \auspice\ provides 5.4$\times$-11.2$\times$ lower lookup latency than \codons, a DHT-based scheme which replicates names based on popularity.
\item
\emph{Capacity:} \auspice\  sustains  a request load that is 18$\times$ the maximum load sustained by a replicate-everywhere scheme, and is comparable to the maximum load sustained by DHT-based designs.
\item
\emph{Comparison to managed DNS:} \auspice\ achieves lookup latencies comparable to a leading managed DNS provider with only one-third the locations of name resolvers. \auspice\ provides a median update latency that is 1.1 sec to 24.7 sec lower than the median update latencies of managed DNS providers.
\item
\emph{Mid-session mobility:} MSocket library enables seamless end-user mobility by migrating a TCP connection from Wi-Fi to 4G in three round trip times.
\end{itemize}
}



\vspace{-0.1in}
\subsection{Experimental setup}
%We first evaluate the latency and cost benefits of \auspice's demand-aware placement against static placement schemes. %and (2) the scalability of \auspice\ with the number of names over several orders of magnitude.
%\subsubsection{Experiment setup}

\textbf{Testbeds:} We use geo-distributed testbeds (Amazon EC2 or Planetlab) or local emulation clusters (EC2 or a departmental cluster) depending upon the experiment's goals. %The departmental cluster consists of 16 machines  (Xeon 5140, 4-core, 8 GB RAM)  and the EC2 instances are ``m3.xlarge" with 15GB RAM. %\tbd{Emulab.}


\textbf{Workload:} There is no real workload today of clients querying a name service in order to communicate with mobile devices frequently moving across different network addresses, both because such a name service does not exist and mobile devices do not have publicly visible IP addresses. So we conduct an evaluation using synthetic workloads for device names (Section \ref{sec:comparison}), but to avoid second-guessing future workload patterns, we conduct a comprehensive sensitivity analysis against all of the relevant parameters such as the read rate, write rate, popularity, and geo-locality of demand \cite{techreport}.

%A vexing evaluation  challenge is that we do not have a workload of clients querying a name service in order to communicate with mobile devices moving across different network addresses. There is no global name resolution infrastructure for mobile device names today and most mobile devices do not have publicly visible addresses, so no one queries for them.

The following are default experimental parameters %(except for Section \ref{sec:sensitivity} on sensitivity analysis) 
for {\em device names}. The ratio of the total number of lookups across all devices to the total number of updates is 1:1, i.e., devices are queried for on average as often as they change addresses. The lookup rate of any single device name is uniformly distributed between 0.5--1.5$\times$ the average lookup rate; the update rate is similarly distributed and drawn independently.%, so there is no correlation between the lookup and update rate of a name.

\rmCR{
\begin{table}[t]
\centering
\small{
\begin{tabular}{c|c}
{\bf Workload parameter} & {\bf Value} \\ \hline
Fraction of (highly mobile) device names & 90\%  \\ \hline
Fraction of (mostly static) service names & 10\%   \\ \hline
\% of device name lookups   & 33.33\%  \\ \hline
\% of device name updates  & 33.33\% \\ \hline
\% of service name lookups   & 33.33\%  \\ \hline
\% of service name updates  & 0.01\% \\ \hline
Geo-locality: [devices, services] & [0.75, 0.8]  \\ \hline
\end{tabular}
}
\caption{Default workload parameters. %(except Section \ref{sec:sensitivity}).
}
\vspace{-0.15in}
\label{tab:setup}
\end{table}
}

\begin{figure*}[t]
\subfigure[Lookup latencies (load = 0.3)]{\label{fig:namesquerymediancdf}\includegraphics[scale=0.5]{graph/newgraphs/lookup-latency-cdf.pdf}}
\subfigure[Lookup latency vs. load]{\label{fig:load}\includegraphics[scale=0.5]{graph/newgraphs/load-latency.pdf}}
\subfigure[Update cost vs. load]{\label{fig:loadupdatecost}\includegraphics[scale=0.5]{graph/newgraphs/load-updatecost.pdf}}
%\subfigure[Update cost]{\label{fig:updatebw}\includegraphics[scale=0.55]{graph/newgraphs/cdf-update-cost.pdf}}
\caption{\small{\auspice\ has up to 5.7$\times$ to 9$\times$ lower latencies than \staticthree\ and \codons\ reps. (\ref{fig:load}). A load of 1 means 200 lookups/sec and 100 updates/sec per name server. \replicateall\ peaks out at a load of 0.3 while \auspice\ can sustain a request load of up to 8 as it carefully chooses between 3 and 80 replicas per name.}}
\vspace{-0.15in}
\label{fig:lookupupdate}
\end{figure*}


How requests are geographically distributed is clearly important for evaluating a replica placement scheme.  We define the {\em geo-locality} of a name as the fraction of requests from the top-10\% of regions where the name is most popular. This parameter ranges from 0.1 (least locality) to 1 (high locality). For a device name with  geo-locality of $g$,  a fraction $g$ of the requests are assumed to originate from 10\% of the local name servers, the first of which is picked randomly and the rest are the ones geographically closest to it. We pick the geo-locality $g=0.75$ for device names, i.e., the top 10\% of regions in the world will account for 75\% of requests, an assumption that is consistent with the finding that communication and content access exhibits a high country-level locality \cite{twitter-www}, and is consistent with the measured geo-locality (below) of service names today.

In addition to device names, {\em service names} constitute a small fraction (10\%) of names and are intended to capture domain names like today with low mobility. Their lookup rate (or popularity) distribution and geo-distribution are used directly from the Alexa dataset \cite{alexa}. Using this dataset, we calculated the geo-locality exhibited by the top 100K websites to be 0.8. Updates for service names are a tiny fraction ($0.01\%$) of lookups as web services can be expected to be queried much more often than they are moved around. The lookup rate of service names is a third of the total number of requests (same as the lookup or update rates of devices).

%Table \ref{tab:setup} summarizes the default workload parameters.


{\textbf{Replication schemes compared:}}
%\label{sec:schemes}
\textbf{\auspice} uses the replica placement strategy as described in Section \ref{sec:design} with the default parameter values $F=3, \mu = 0.7, \nu = 0.5$. %We set the replication control parameter ($\beta$)  to ensure that the utilization of the servers remains below  70\% (refer to Equation \ref{eq:mu}). 
We compare \auspice\ against the following: (1) \textbf{\staticthree} replicates each name at three random locations; (2) \textbf{\replicateall} replicates all names at all locations; (3) \textbf{\codons} replicates names using consistent hashing with replication similar to Codons\cite{codons-paper}. The number of replicas is chosen based on the popularity ranking of a name and  the location of replicas is decided by consistent hashing. The average hop count in Codons's underlying Beehive algorithm  is set so that it creates the same average number of replicas as \auspice\ for a fair comparison. All schemes direct a lookup to the closest available replica after the first request.

%In our implementation, each request is directly sent to the replica  that would have received this request if Pastry  routing were followed, i.e., the latency we report would be smaller than the actual latency in \codons.   We set the Zipf exponent to be $0.63$ calculated based on our workload. The average hop count is set so that \codons\ creates the same number of replicas as  \auspice\ for a fair comparison.


\eat {
\begin{figure*}[t]
\vspace{0.05in}
\begin{minipage}[b]{0.3\linewidth}
\centering
\includegraphics[scale=0.55]{graph/newgraphs/update-latency-cdf.pdf}
\caption{Median update latency of \auspice\ with total write ordering per name is 284ms and is comparable to other  schemes. } 
\label{fig:updates}
\end{minipage}
\hspace{0.3cm}
\begin{minipage}[b]{0.35\linewidth}
\centering
\includegraphics[scale=0.55]{graph/camera-ready/connect-time-eventual.pdf}
\caption{Time-to-connect $\approx$ lookup latency for moderate mobility rates ($<$1/100s)  as \auspice\ returns up-to-date responses w.h.p., but sharply rises thereafter (as per Eq. \ref{eq:ttc}).}
\label{fig:ttc}
\end{minipage}
\hspace{0.3cm}
\begin{minipage}[b]{0.3\linewidth}
\centering
\includegraphics[scale=0.55]{graph/camera-ready/latency_by_time.pdf}
\caption{\auspice\ adapts to varying demand geo-locality in two epochs each 75s long with a (tunable) reconfiguration message overhead of 3.6\%.}
\label{fig:latency-time}
\end{minipage}
%\vspace{-0.25in}
\end{figure*}
% Box plot shows min, 5th \%-ile, median, 95th \%-ile, and max. Asterisk shows the mean.
}


\vsp
\subsection{Evaluating \auspice's replica placement}
\label{sec:comparison}

We conduct experiments in this subsection on a 16-node (each with Xeon 5140, 4-cores, 8 GB RAM) departmental cluster, wherein each machine hosts 10 instances of either nameservers or local nameservers so as to emulate an 80-nameserver \auspice\ deployment. We instrument the instances so as to emulate wide-area latencies between any two instances that correspond to 160 randomly chosen Planetlab nodes. We choose emulation instead of a geo-distributed testbed in this experiment in order to obtain reproducible results while stress-testing the load-vs.-response time scaling behavior of various schemes given identical resources.

\vsp
\subsubsection{Lookup latency and update cost}
\label{sec:lookup}
\label{sec:lowload}


How well does \auspice\ use available resources for replicating name records? To evaluate this, we compare the lookup latency of schemes across varying load levels. A machine running 10 name servers receives on average 2000 lookups/sec and 1000 updates/sec at a load = 1. For each scheme, load is increased  until  2\% of requests fail, where a failed request means no response is received within 10 sec. The experiment runs for 10 mins for each scheme and load level. To measure steady-state behavior, both \auspice\ and \codons\ pre-compute the placement at the start of the experiment based on prior knowledge of the workload.%and retain the set of active replicas during the experiment. 

Figure \ref{fig:namesquerymediancdf} shows the distribution of median lookup latency across names at the smallest load level (load = 0.3).  Figure \ref{fig:load} shows load-vs-lookup latency curve for schemes, where ``lookup latency" refers to the mean of the median lookup latencies of names. Figure \ref{fig:loadupdatecost} shows the corresponding mean of the distribution of update cost across names at varying loads; the update cost for a name is the number of replicas times the update rate of that name.


{\em{\replicateall}}   gives low lookup latencies at the smallest load level, but generates a very high update cost and can sustain a request load of at most 0.3. This is further supported by  Figure \ref{fig:loadupdatecost} that shows that the update cost for \replicateall\ at load = 0.4 is more than the update cost of \auspice\  at load = 8. In theory, \auspice\ can have a capacity advantage of up to N/M over \replicateall, where N is the total number of name servers and M is the minimum of replicas \auspice\ must make for ensuring fault tolerance (resp. 80 and 3 here). {\em{\staticthree}} can sustain a high request load (Fig. \ref{fig:load}) due to its low update costs, but its lookup latencies are higher as it only creates 3 replicas randomly. %In theory, at low loads, \auspice\ can incur up to N/3 times more replication cost than \staticthree\ (but gain latency benefits), while at high loads, \auspice\ incurs an update cost comparable to \staticthree\ with a modest latency benefit because of better replica placement.

{\em{\auspice}}  has $5.7\times-9\times$ lower latencies over \staticthree\ and \codons\ respectively (Figure \ref{fig:load}, load=1). This is because it places a fraction of the replicas close to pockets of high demand unlike the other two.  At low to moderate loads, servers have excess capacity than the minimum needed for fault tolerance, so \auspice\ creates as many replicas as it can without exceeding the threshold utilization level (Eq. \ref{eq:mu}), thereby  achieving low latencies for loads$\leq$4. 
At loads $\geq$ 4, servers exceed the threshold utilization level even if \auspice\ creates the minimum number of replicas needed for fault tolerance. This explains why \auspice\ and \staticthree\ have equal update costs for loads $\geq$ 4 (Figure \ref{fig:loadupdatecost}). Reducing the number of replicas at higher loads allows \auspice\ to limit the update cost and sustain a maximum request load that is equal to \staticthree. 

{\em{\codons}}  has higher lookup latencies as it replicates based on lookup popularity alone and places replicas using consistent hashing without considering the geo-distribution of demand. Further, it answers lookups from a replica selected enroute the DHT route. Typically, the latency to the selected replica  is higher than the latency to the closest replica for a name, which results in high latencies.  \codons\ replicates 22.3\%   most popular names at all locations. Lookups for these names go to the closest replica and achieve low latencies; lookups for remaining 77.7\% of names incur high latencies.

\codons\  incurs higher update costs than \auspice\   even though both schemes create nearly equal numbers of replicas at every load level. This is because \codons\ decides the number of replicas of a name only based on its popularity, i.e., lookup rates, while \auspice\ decides the number of replicas based on lookup-to-update ratio of names. Due to its higher update costs, \codons\  can not sustain as high a request load as \auspice.

\begin{figure*}[t]
\subfigure[E2E time-to-connect]{\label{fig:ttc_msocket}\includegraphics[width=2.4in,height=1.8in]{graph/camera-ready/connect-time-msocket.pdf}}
\subfigure[Simultaneous mobility]{\label{fig:SimulMig}\includegraphics[width=2.5in, height=1.8in]{figure/SimulMig.pdf}}
\subfigure[Context-aware delivery]{\label{fig:5MemberTimeline}\includegraphics[width=2in, height=1.8in]{figure/5MemTimeLineUsed.pdf}}
\caption{(a) Time-to-connect$\approx$lookup latency for moderate mobility rates ($<\frac{1}{10s}$)  as \auspice\ returns up-to-date responses w.h.p., but sharply rises thereafter (Eq. \ref{eq:ttc}); (b) Simultaneous mobility recovery in $\approx$2 RTTs after both endpoints resurface; (c) Context-aware delivery showing 3 messages  geo-cast to 5 members.}
\label{fig:end2end}
\end{figure*}




\vsp
\subsubsection{Update latency, update propagation delay}
\label{sec:updatelatency}

\eat{
\begin{figure}[h]
\centering
\includegraphics[scale=0.55]{graph/newgraphs/update-latency-cdf.pdf}
%\includegraphics[scale=0.55]{graph/system-exp/cdf-names-median-update.pdf}
\vspace{-0.2in}
\caption{[System] Median update latency of \auspice\ is 284ms and is comparable to those of other schemes.} 
%The high latencies for \replicateall\ are because of insufficient upload capacity on PlanetLab.}
\label{fig:updates}
\vspace{-0.1in}
\end{figure}


\begin{figure}
\centering
\includegraphics[scale=0.55]{graph/newgraphs/managed-update.pdf}
\vspace{-0.1in}
\caption{Median  update latency of \auspice\ for updating replicas at 5 locations is  1.0 sec to 24.7 sec lower than three managed DNS providers. Values shown are 5, 25, 50, 75,  and 95 percentiles.}
\vspace{-0.2in}
\label{fig:manageddnsupdate}
\end{figure}


\begin{figure}[t]
\includegraphics[scale=0.5]{graph/medianlatencyVSlocality.pdf}
\vspace{-0.1in}
\caption{[Simulator] Workload sensitivity. \auspice\ gives 2$\times$ to 5$\times$  lower latencies across all locality levels.}
\label{fig:varylocality}
\vspace{-0.1in}
\end{figure}

}
%\subfigure{\label{fig:updatelatency}\includegraphics[scale=0.55]{graph/newgraphs/}}

%This experiment evaluates the update latency of schemes.


The {\em client-perceived update latency}, i.e., the time from when when a client sends an update to when it receives a confirmation. %with total write ordering is shown in Figure \ref{fig:updates}.  
These numbers are measured from the experiment in Section \ref{sec:lookup} for load=0.3. The median and 90th percentile update latency for \auspice\ with total write ordering is 284ms and is comparable to other schemes. A request, after arriving an active replica, takes four one-way network delays (two rounds) to be committed by Paxos. The median update latency is a few hundred milliseconds for all schemes as it is dominated by update propagation delays.

The {\em update propagation delay}, i.e., the time from when a client issued a write till the last replica executes the write, is a key determiner of the time-to-connect. As shown in Section \ref{sec:scalability}, with eventual consistency, update propagation takes one round, while with total write ordering, update propagation takes two rounds and 50\% more messages.

The measured update propagation delay is consistent with expectations. With eventual consistency, this delay is 154 ms, while with total write ordering, it is 292ms. Thus. the cost of the stronger consistency provided by total write ordering compared to eventual is that it can increase the time-to-connect latency by up to 2$\times$. Note that the 2$\times$ inflation is a worst-case estimate, i.e., it will impact the time-to-connect latency only if a read request arrives at a replica while a write is under propagation to that replica, as we show below.







\eat {
\begin{figure}[t]
\vsp
\centering
\includegraphics[width=2.4in,height=1.5in]{graph/camera-ready/connect-time-eventual.pdf}
\figvsp
\caption{Time-to-connect $\approx$ lookup latency for moderate mobility rates ($<$1/100s)  as \auspice\ returns up-to-date responses w.h.p., but sharply rises thereafter (as per Eq. \ref{eq:ttc}).}
\label{fig:ttc}
\figvsp
\end{figure}
}

%The time-to-connect to a mobile name for a client is the sum of the time to get the correct address of the mobile and the TCP connection setup latency. As the latter latency is independent of the \auspice's design, we measure the former latency.  Our experiment setup on PlanetLab consists of a single (virtual) client and a single (virtual) mobile co-located with distinct local name servers.  The mobile's name record is stored on three name servers, and is updated by the mobile during an experiment. The client reads the mobile's  name record from \auspice\ and  verifies if the value in the name record is correct by establishing a TCP connection to the mobile on a fixed address.  On an incorrect response, the client retries the lookup after a timeout of 5 sec.  We run five experiments of 10 min each by varying the update rate of the mobile from 0.0001 updates/s to 1 update/s; the client sends  lookup at a rate of 10/sec in each case. The inter-arrival times between lookups (updates) follow an exponential distribution. 
%\tbd{We have also validated that the time-to-connect observed using msocket yields values close to this observed in the experiment above.}

%This model, included in our tech report \cite{techreport}, calculates time-to-connect $C$ as a function of lookup latency $l$, update latency $u$, update rate $r$, and connect-timeout $T$ as follows: $C = l + (1-e^{-r u})(l + T)/e^{-r u}$.   In Figure \ref{fig:ttc}, the time-to-connect values predicted by the model are comparable to actual mean time-to-connect values across all update rates, which further validates our findings.  Overall, our results show that for expected mobility rates Auspice returns correct responses on first lookup with high probability, thereby ensuring low time-to-connect for clients.


%\subsubsection{Choosing group change epoch length}
%\label{sec:gc-analysis}
%\auspice\ chooses group length epochs so that the overhead of group changes is a small fraction of overall load and the system is responsive to changes in demand geo-distribution.  First, we quantify the message overhead for a group change of a single name. We denote number of replica controllers by $M$, and the number of old (new) replicas by $r_1$ ($r_2)$.  Note that ordering a single request via paxos uses $cn$ messages, where $n$ is the number of replicas and c (= 3) is a constant.  The message overhead of each step in group change is as follows: (1) replica controllers agreeing to a new set of replicas = $cM$ (2) old active replicas stopping their paxos instance = $cr_1$ (3) informing new active replicas of reconfiguration = $2r_2$ (4) replica controllers agreeing that group change is complete = $cM$.  Next, we quantify the total rate of messages due to read and write requests in the system for the case of totally ordered writes. The total message rate is equal to $\sum_i (r_i + c n_i w_i)$, where  $r_i$, $w_i$, and $n_i$ are respectively the read rate, the write rate, and the current number of replicas for name $i$. 


%To limit the overhead of reconfiguration to say 5\%, the epoch length is set to (group change overhead for all names)/(total rate of read and write messages)/5\%.  To account for the fact that only a fraction of names may be reconfigured in an epoch, we multiply the epoch length $T$ by the expected fraction of names that may be reconfigured. We assume that the expected fraction is equal to the fraction of names reconfigured in the previous epoch.  In our implementation, each node first independently calculates an epoch length based on statistics for names stored at that node, and broadcasts it to all other nodes once in each epoch. Finally, the epoch length is chosen by taking the average of epoch length of all nodes.


\rmCR{
\subsubsection{Reconfiguration overhead vs. responsiveness}

\blue{
In the next experiment, we show how \auspice\ can choose the epoch length and reconfiguration trigger so as to limit the overhead of reconfiguration (as in Section \ref{sec:reconf_policy}) while being responsive to changes in demand geo-locality. The workload changes the geo-distribution of demand for each name every 300 sec. 
For each name, we change the regions from which most requests arise so that changing the placement of replicas becomes necessary to minimize lookup latencies. The experiment is performed on a local cluster with a workload of 1000 names with characteristics as described in Table \ref{tab:setup}. 
The epoch length of group changes is chosen to be 75 sec, which ensures that group changes result in less than 10\% overhead to the system (Section \ref{sec:reconf_policy}). 
}

\blue{
We show the lookup latencies of \auspice\ and the message overhead of reconfiguration in the experiment in Figue \ref{fig:latency-time}.   We find that \auspice\ takes two epochs to infer a change in the geo-distribution of demand and to adapt to it.  This result suggests that \auspice\ can optimize lookup latencies provided the geo-distribution of demand for a name remains stable for a few epochs.
Further, we measured the overhead of reconfiguration messages in this experiment to be 3.6\%. The overhead is less than the expected overhead of 10\% because not all names are reconfigured in every epoch. 
%This finding shows that choosing epoch lengths as per the analysis in  Section \\ref{sec:gc-analysis} keeps the overhead of group changes to a small fraction of the overall system load.
}
}


